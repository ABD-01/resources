## Computer Vision

##### Extracting information from Images, that help robots “see” and “perceive” as humans do, and understand it’s environment using input from it’s camera.

### Course 

[**Introduction to Computer Vision by Aaron Bobbick**](https://www.udacity.com/course/introduction-to-computer-vision--ud810) 

This will build the foundation for Computer Vision. It also gives sufficient information on Digital Image Processing and the concepts that will be required for the same. If someone watches all the lectures, they are ready to work on a good project in this field. It is recommended that the student is proficient in either MATLAB/Octave or Python. If you are opting for Python, make sure to check out [NumPy](https://numpy.org/) (helpful, but not necessary) and [OpenCV](https://docs.opencv.org/) (for Python. Read up to and including [Image Processing in OpenCV](https://docs.opencv.org/4.1.2/d6/d00/tutorial_py_root.html)), which are the associated libraries that will help you to implement many of the concepts. If one does the first 20% (we encourage anyone who takes this course to watch it till the end) of the course too, then he/she will be able to implement a virtual drawing pad, which requires some basic, but power image processing techniques. As one dives into the concept of features, the student will be able to implement more powerful algorithms that will help in projects such as stitching of two images for making panorama, camera calibration to estimate the focal length of the camera using just the camera feed, removal of distortion from the camera output using mathematical techniques, etc.

**Example:** Laptops can be controlled by face gestures (blink to clock, turn head to move mouse, etc).

##### Mentors:

* Arihant Gaur

* Saurabh Kemekar

* Mayank Bumb

* Aayush Fadia

